ğŸ” GitHub Chatbot (Local LLM)
A fully local chatbot that enables natural language querying of GitHub repositories. It indexes code and documentation from selected repos, then allows conversational queries using FAISS, LangChain, and Mistral (via Ollama) â€” all without requiring internet access.

Built with:

ğŸ§  LangChain

ğŸ“¦ FAISS

ğŸ§¬ HuggingFace Transformers

ğŸ“„ Unstructured

ğŸŒ Streamlit

ğŸ¤– Ollama for running Mistral locally

âš™ï¸ 1. Prerequisites
Install the following on your system before starting:

Python 3.10+

Git

pip

virtualenv (recommended)

Ollama (to run mistral or other local LLMs)

Then pull the Mistral model:

bash
Copy
Edit
ollama pull mistral
ğŸ“¦ 2. Project Setup (From Scratch)
bash
Copy
Edit
# Clone the repo
git clone git@github.com:Gutman-Lab/GitHub-Chatbot-Local-LLM.git

# Navigate into project directory
cd GitHub-Chatbot-Local-LLM
ğŸ§ª 3. Create and Activate Virtual Environment
bash
Copy
Edit
python3 -m venv venv
source venv/bin/activate  # or 'venv\Scripts\activate' on Windows
ğŸ“¥ 4. Install Dependencies
bash
Copy
Edit
pip install -r requirements.txt

# Additional packages (if not included)
pip install -U langchain-community
pip install unstructured tiktoken chardet
ğŸ“ 5. Project Structure
bash
Copy
Edit
GitHub-Chatbot-Local-LLM/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ ingest/
â”‚   â”‚   â””â”€â”€ github_scraper.py         # Downloads GitHub repos
â”‚   â”œâ”€â”€ vectorstore/
â”‚   â”‚   â””â”€â”€ store_embeddings.py       # Embeds files with LLM encoder
â”‚   â””â”€â”€ chat/
â”‚       â””â”€â”€ rag_chat.py               # RAG pipeline using FAISS + Mistral
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ streamlit_app.py              # Chat interface using Streamlit
â”œâ”€â”€ data/                             # Downloaded repositories go here
â”œâ”€â”€ .env                              # Environment config
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ”„ 6. Clone GitHub Repositories to Query
Run the scraper script to download public GitHub repositories into the data/ folder:

bash
Copy
Edit
python backend/ingest/github_scraper.py
ğŸ“ You may edit the script to customize the repository URLs you want to scrape.

ğŸ§  7. Generate Embeddings
After downloading the repos, generate vector embeddings:

bash
Copy
Edit
python backend/vectorstore/store_embeddings.py
This will embed the documents using a HuggingFace model and store them in a FAISS index.

ğŸ’¬ 8. Launch the Chatbot Interface
Start the Streamlit-based UI:

bash
Copy
Edit
streamlit run frontend/streamlit_app.py
Open your browser at: http://localhost:8501

ğŸ§ª 9. Example Questions to Try
You can ask natural language queries like:

â€œWhat does the function parse_slide_metadata do?â€

â€œExplain how job tracking is handled in job_tracker.php.â€

â€œWhich file contains the SLURM job duration analysis?â€

â€œWhat is HistomicsUI used for?â€

â€œWhere is the Dockerfile located in the repository?â€

â€œWhat is the purpose of the Digital Slide Archive?â€

â€œHow does HistomicsUI interact with the Girder backend?â€

â€œWhat are the core components of HistomicsTK?â€

â€œWhich file contains plugin definitions for HistomicsUI?â€

â€œHow are image annotations stored and retrieved?â€

âœ… Final Checklist
 âœ… Python + pip installed

 âœ… Ollama with Mistral pulled

 âœ… Repo cloned

 âœ… Virtualenv activated

 âœ… All dependencies installed

 âœ… GitHub repos scraped

 âœ… Embeddings generated

 âœ… Streamlit app running

